{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages \n",
    "\n",
    "- change the below markdown chunk to code chunk if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install llama_index\n",
    "!pip install langchain_openai\n",
    "!pip install langchain_community\n",
    "!pip install langgraph\n",
    "!pip install retriever\n",
    "!pip install chromadb\n",
    "!pip install llama-index-utils-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from glob import glob\n",
    "import openai\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from llama_index.core.node_parser import LangchainNodeParser, SentenceWindowNodeParser,SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.extractors import BaseExtractor,KeywordExtractor,TitleExtractor\n",
    "from llama_index.core import Settings,SimpleDirectoryReader,StorageContext,VectorStoreIndex,load_index_from_storage, Document\n",
    "from llama_index.core.schema import MetadataMode\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Settings---------- #\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "Settings.llm = OpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=openai.api_key,\n",
    "    temperature=0.1\n",
    ")\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_key=openai.api_key,\n",
    "    embed_batch_size=100\n",
    ")\n",
    "Settings.text_splitter = SentenceSplitter(chunk_size=512,chunk_overlap=50)\n",
    "\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=5,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "Settings.node_parser = node_parser\n",
    "\n",
    "# Paths for storage\n",
    "DB_DIR = os.getenv(\"DB_DIR\", os.path.join(os.getcwd(), \"docs\", \"chroma\"))\n",
    "INDEX_DIR = os.getenv(\"INDEX_DIR\", os.path.join(os.getcwd(), \"index\"))\n",
    "METADATA_ENRICHMENT_INDEX_DIR = os.getenv(\"METADATA_ENRICHMENT_INDEX_DIR\", os.path.join(os.getcwd(), \"enriched_index\"))\n",
    "\n",
    "# Folder containing the PDF files\n",
    "DATA_FOLDER = os.getenv(\"DATA_FOLDER\", os.path.join(os.getcwd(), \"docs\"))\n",
    "\n",
    "# Settings end----- #\n",
    "\n",
    "class CustomExtractor(BaseExtractor):\n",
    "    def extract(self, nodes):\n",
    "        metadata_list = [\n",
    "            {\n",
    "                \"custom\": (\n",
    "                    node.metadata[\"document_title\"]\n",
    "                    + \"\\n\"\n",
    "                    + node.metadata[\"excerpt_keywords\"]\n",
    "                )\n",
    "            }\n",
    "            for node in nodes\n",
    "        ]\n",
    "        return metadata_list\n",
    "\n",
    "def metadata_enrichment_index(files=DATA_FOLDER, documents=None):\n",
    "    \"\"\"\n",
    "    Create an enriched index with transformations.\n",
    "    returns Enriched index with metadata\n",
    "    \"\"\"\n",
    "    nest_asyncio.apply()\n",
    "    extractors = [\n",
    "        TitleExtractor(nodes=5, llm=Settings.llm),\n",
    "        KeywordExtractor(keywords=10, llm=Settings.llm)\n",
    "    ]\n",
    "    transformations = [Settings.node_parser] + extractors\n",
    "    pipeline = IngestionPipeline(transformations=transformations)\n",
    "    docs_nodes = []\n",
    "\n",
    "    if documents:\n",
    "        docs_nodes.extend(pipeline.run(documents=documents))\n",
    "    else:\n",
    "        file_paths = glob(os.path.join(files, \"*.pdf\")) if isinstance(files, str) else files\n",
    "        for file_path in file_paths:\n",
    "            docs = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "            docs_nodes.extend(pipeline.run(documents=docs))\n",
    "    \n",
    "    index = VectorStoreIndex(nodes=docs_nodes,embed_model=Settings.embed_model)\n",
    "    index.storage_context.persist(persist_dir=METADATA_ENRICHMENT_INDEX_DIR)\n",
    "    \n",
    "    return index\n",
    "\n",
    "def llama_index_chunk_pdf(files=DATA_FOLDER, index_dir=METADATA_ENRICHMENT_INDEX_DIR):\n",
    "    \"\"\"\n",
    "    Load/create new one from PDF files.\n",
    "    \"\"\"\n",
    "    if os.path.exists(index_dir):\n",
    "        return load_index_from_storage(StorageContext.from_defaults(persist_dir=index_dir))\n",
    "    \n",
    "    file_paths = [os.path.join(files, f) for f in os.listdir(files) if f.endswith('.pdf')]\n",
    "    documents = SimpleDirectoryReader(input_files=file_paths).load_data()\n",
    "    document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "    \n",
    "    return metadata_enrichment_index(documents=document)\n",
    "\n",
    "def main():\n",
    "    \"\"\"execute chunking process\"\"\"\n",
    "    llama_index_chunk_pdf(files=DATA_FOLDER)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval & Engine\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoModel, AutoTokenizer\n",
    "from langchain_core.tools import tool\n",
    "from llama_index.core import Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor#, SentenceTransformerRerank\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.question_gen import LLMQuestionGenerator\n",
    "from llama_index.core.question_gen.prompts import DEFAULT_SUB_QUESTION_PROMPT_TMPL\n",
    "\n",
    "'''settings'''\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=10,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature= 0.1, timeout=60)\n",
    "Settings.node_parser = node_parser\n",
    "\n",
    "def get_sentence_window_query_engine(sentence_index, similarity_top_k=6):\n",
    "    \"\"\"\n",
    "    Create a sentence window query engine from index.\n",
    "    \"\"\"\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k,\n",
    "        node_postprocessors=[postproc]\n",
    "    )\n",
    "    return sentence_window_engine\n",
    "\n",
    "def final_engine(engine, verbose=False):\n",
    "    \"\"\"\n",
    "    Create final query engine with sub-question capability.\n",
    "    \"\"\"\n",
    "    question_gen = LLMQuestionGenerator.from_defaults(\n",
    "        llm=Settings.llm,\n",
    "        prompt_template_str=\"\"\"\n",
    "            Instead of giving a question, always prefix the question\n",
    "            with: 'By first identifying and quoting the most relevant sources, '.\n",
    "            \"\"\" + DEFAULT_SUB_QUESTION_PROMPT_TMPL,\n",
    "    )\n",
    "    return SubQuestionQueryEngine.from_defaults(\n",
    "        query_engine_tools=[\n",
    "            QueryEngineTool(\n",
    "                query_engine=engine,\n",
    "                metadata=ToolMetadata(\n",
    "                    name=\"docs\",\n",
    "                    description=\"ESG information and portfolio constructions on companies.\",\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        question_gen=question_gen,\n",
    "        use_async=True,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "def llama_index_retriever_tool(index_path: str, index_type='sentence', similarity_top_k=6):\n",
    "    \"\"\"\n",
    "   Alows searching and retrieving information from documents using llama-index.\n",
    "    \"\"\"\n",
    "    # Load the index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    \n",
    "    # Create query engine\n",
    "    query_engine = get_sentence_window_query_engine(index, similarity_top_k) if 'sentence' in index_type else index.as_query_engine(similarity_top_k=similarity_top_k)\n",
    "    query_engine = final_engine(query_engine, verbose=True)\n",
    "    \n",
    "    @tool\n",
    "    def engine(query=''):\n",
    "        \"\"\"\n",
    "        RAG query tool.\n",
    "        \"\"\"\n",
    "        response = query_engine.query(query)\n",
    "        print(f'---RAG---:\\n {response}')\n",
    "        return response\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, Sequence, TypedDict\n",
    "from langchain import hub\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "MAX_ATTEMPT = 5\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The add_messages function defines how an update should be processed\n",
    "    # Default is to replace. add_messages says \"append\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    attempt_num: int\n",
    "\n",
    "\n",
    "### Edges\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\", \"generate_no_ans\"]:\n",
    "   \"\"\"\n",
    "   Determines whether the retrieved documents are relevant to the question.\n",
    "   \"\"\"\n",
    "   print(\"---CHECK RELEVANCE---\")\n",
    "   \n",
    "   try:\n",
    "       messages = state[\"messages\"]\n",
    "       question = messages[0].content\n",
    "       print('Question:', question)\n",
    "       \n",
    "       # Use llama-index for retrieval if index_path provided\n",
    "       if \"index_path\" in state:\n",
    "           retriever = llama_index_retriever_tool(\n",
    "               index_path=state[\"index_path\"],\n",
    "               index_type='sentence',\n",
    "               similarity_top_k=10  # Increased for better coverage\n",
    "           )\n",
    "           \n",
    "           # Get retrieval results\n",
    "           retrieval_response = retriever(question)\n",
    "           docs = str(retrieval_response)\n",
    "           \n",
    "           # Normalize text for matching\n",
    "           question_lower = question.lower()\n",
    "           docs_lower = docs.lower()\n",
    "           \n",
    "           # Extract year and check for temporal+numeric relevance \n",
    "           import re\n",
    "           year_match = re.search(r'20\\d{2}', question)\n",
    "           if year_match:\n",
    "               year = year_match.group()\n",
    "               has_year = year in docs_lower\n",
    "               has_numbers = bool(re.search(r'(?:rm|myr|rp)?\\s*\\d+(?:\\.\\d+)?(?:\\s*(?:million|m|billion|b))?', docs_lower))\n",
    "               \n",
    "               if has_year and has_numbers:\n",
    "                   print(\"---DECISION: DOCS RELEVANT (Contains Year and Numbers)---\")\n",
    "                   print(\"docs:\")\n",
    "                   print(docs)\n",
    "                   return \"generate\"\n",
    "               \n",
    "       else:\n",
    "           docs = messages[-1].content\n",
    "           \n",
    "       print(\"Retrieved docs:\", docs)\n",
    "       \n",
    "       # Grade relevance using LLM\n",
    "       class grade(BaseModel):\n",
    "           binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "       \n",
    "       model = ChatOpenAI(temperature=0.1, model=MODEL_NAME, streaming=True)\n",
    "       llm_with_tool = model.with_structured_output(grade)\n",
    "       \n",
    "       prompt = PromptTemplate(\n",
    "           template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question about financial and ESG data. \\n \n",
    "           Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "           Here is the user question: {question} \\n\n",
    "           \n",
    "           For financial questions, grade the document as relevant if it contains:\n",
    "           1. Specific numeric values (like revenue, profit, etc.) for the requested time period\n",
    "           2. Financial figures with currency indicators (USD, MYR, RM, etc.)\n",
    "           3. Year-specific financial information that matches the question\n",
    "           4. Comparative financial data between years\n",
    "           \n",
    "           The document should be considered relevant even if it needs some interpretation \n",
    "           (e.g., if asking about 2023 and document mentions 'FY2023' or 'current year').\n",
    "           \n",
    "           If the document only states that information is not found or not available, grade it as not relevant.\n",
    "           Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question.\"\"\",\n",
    "           input_variables=[\"context\", \"question\"],\n",
    "       )\n",
    "       chain = prompt | llm_with_tool\n",
    "\n",
    "       scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "       score = scored_result.binary_score\n",
    "\n",
    "       # Return decision based on score and attempt count\n",
    "       if score == \"yes\":\n",
    "           print(\"---DECISION: DOCS RELEVANT---\")\n",
    "           print(\"docs:\")\n",
    "           print(docs)\n",
    "           return \"generate\"\n",
    "       elif state[\"attempt_num\"] < MAX_ATTEMPT:\n",
    "           print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "           print(score)\n",
    "           print(\"docs:\")\n",
    "           print(docs)\n",
    "           return \"rewrite\"\n",
    "       else:\n",
    "           print(\"---DECISION: DOCS NOT RELEVANT, MAX_ATTEMPT achieved---\")\n",
    "           print(score)\n",
    "           print(\"docs:\")\n",
    "           print(docs)\n",
    "           return \"generate_no_ans\"\n",
    "           \n",
    "   except Exception as e:\n",
    "       print(f\"Error in grade_documents: {str(e)}\")\n",
    "       raise\n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def agent_with_tools(tools):\n",
    "    def agent(state):\n",
    "        \"\"\"\n",
    "        Invokes the agent model to generate a response based on the current state. Given\n",
    "        the question, it will decide to retrieve using the retriever tool, or simply end.\n",
    "        \"\"\"\n",
    "        print(\"---CALL AGENT---\")\n",
    "        messages = state[\"messages\"]\n",
    "        if not state.get(\"attempt_num\"):\n",
    "            state[\"attempt_num\"] = 0  # Initialize attempt number\n",
    "        model = ChatOpenAI(temperature=0.1, streaming=True, model=MODEL_NAME)\n",
    "        model = model.bind_tools(tools)\n",
    "        response = model.invoke(messages)\n",
    "        # We return a list, because this will get added to the existing list\n",
    "        return {\"messages\": [response], \"attempt_num\": state[\"attempt_num\"]}\n",
    "    return agent\n",
    "\n",
    "\n",
    "\n",
    "def rewrite(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "\n",
    "    msg = [\n",
    "        HumanMessage(\n",
    "            content=f\"\"\" \\n \n",
    "    Look at the input and try to reason about the underlying semantic intent / meaning. \\n \n",
    "    Here is the initial question:\n",
    "    \\n ------- \\n\n",
    "    {question} \n",
    "    \\n ------- \\n\n",
    "    Formulate an improved question: \"\"\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Grader\n",
    "    model = ChatOpenAI(temperature=0.1, model=MODEL_NAME, streaming=True)\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response], \"attempt_num\": state[\"attempt_num\"]+1}\n",
    "\n",
    "def generate_no_ans(state):\n",
    "    \"\"\"\n",
    "    Generate response when no answer found\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE_NO_ANS---\")\n",
    "    return {\"messages\": [\"No Relevant Info found in the documents\"], \"attempt_num\": 0}\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message = messages[-1]\n",
    "    docs = last_message.content\n",
    "    \n",
    "    print(\"Question:\", question)\n",
    "    print(\"Last Message:\", last_message)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    # LLM\n",
    "    llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0.1, streaming=True)\n",
    "\n",
    "    # Post-processing\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    # Chain\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response], \"attempt_num\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "def build_workflow(vecdb):\n",
    "    retriever_tool = llama_index_retriever_tool(vecdb)\n",
    "    tools = [retriever_tool]\n",
    "\n",
    "    # Define a new graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    workflow.attempt_num = 0\n",
    "\n",
    "    # Define the nodes we will cycle between\n",
    "    workflow.add_node(\"agent\", agent_with_tools(tools))  # agent\n",
    "    retrieve = ToolNode(tools)\n",
    "    workflow.add_node(\"retrieve\", retrieve)  # retrieval\n",
    "    workflow.add_node(\"rewrite\", rewrite)  # Re-writing the question\n",
    "    workflow.add_node(\"generate_no_ans\", generate_no_ans)  #  Generating a response after we know no document is relevant\n",
    "    workflow.add_node(\"generate\", generate)  # Generating a response after we know the documents are relevant\n",
    "    # Call agent node to decide to retrieve or not\n",
    "    workflow.add_edge(START, \"agent\")\n",
    "\n",
    "    # Decide whether to retrieve\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        # Assess agent decision\n",
    "        tools_condition,\n",
    "        {\n",
    "            # Translate the condition outputs to nodes in our graph\n",
    "            \"tools\": \"retrieve\",\n",
    "            END: END,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Edges taken after the `action` node is called.\n",
    "    workflow.add_conditional_edges(\"retrieve\", grade_documents)\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "    workflow.add_edge(\"generate_no_ans\", END)\n",
    "    workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "    # Compile\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User question: hi\n",
      "---CALL AGENT---\n",
      "User question: What's Public Shareholders' share for SOL?\n",
      "---CALL AGENT---\n",
      "Generated 3 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[docs] Q: By first identifying and quoting the most relevant sources, what is the percentage of public shareholders' ownership in SOL?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[docs] Q: By first identifying and quoting the most relevant sources, what are the recent changes in public shareholders' share for SOL?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[docs] Q: By first identifying and quoting the most relevant sources, how does the public shareholders' share in SOL compare to industry standards?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[docs] A: The percentage of public shareholders' ownership in Shui On Land (SOL) is 43.77%. This is stated in the excerpt: \"Shui On Group 56.23% Public Shareholders 43.77%.\"\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[docs] A: The recent changes in public shareholders' share for Shui On Land (SOL) indicate that public shareholders hold 43.77% of the company, while the Shui On Group holds 56.23%. This ownership structure reflects a joint ownership arrangement where the total ownership stake is 100% shared between the two parties. There are no specific details provided about recent changes in the percentage of shares held by public shareholders compared to previous figures.\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[docs] A: The public shareholders hold a 43.77% stake in Shui On Land, while the Shui On Group retains a 56.23% share. This ownership structure indicates a significant level of public investment in the company, which is noteworthy given that Shui On Land is the largest Chinese real estate enterprise listed on the Hong Kong Stock Exchange since 2006. \n",
      "\n",
      "However, the context does not provide specific industry standards for comparison regarding public shareholder stakes in similar companies. Therefore, while the ownership distribution is clear, a direct comparison to industry standards cannot be made based on the available information.\n",
      "\u001b[0m---RAG---:\n",
      " Public shareholders hold a 43.77% stake in Shui On Land (SOL).\n",
      "---CHECK RELEVANCE---\n",
      "Question: What's Public Shareholders' share for SOL?\n",
      "Retrieved docs: Public shareholders hold a 43.77% stake in Shui On Land (SOL).\n",
      "---DECISION: DOCS RELEVANT---\n",
      "docs:\n",
      "Public shareholders hold a 43.77% stake in Shui On Land (SOL).\n",
      "---GENERATE---\n",
      "Question: What's Public Shareholders' share for SOL?\n",
      "Last Message: content='Public shareholders hold a 43.77% stake in Shui On Land (SOL).' name='engine' id='d78248ae-4690-4624-90da-baa2a159d629' tool_call_id='call_foawlXQaYl8ZQQnUtiardNde'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gradio as gr\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Gradio Integration\n",
    "def get_answer_func(graph):\n",
    "    def get_answer_chat(question, history):\n",
    "        print(\"User question:\", question)\n",
    "        result = graph.invoke(\n",
    "            {\"messages\": [HumanMessage(content=question)]},\n",
    "            config={\"configurable\": {\"thread_id\": 42, \"max_attempt\": 5}}\n",
    "        )\n",
    "        response = result[\"messages\"][-1].content\n",
    "        history.append((question, response))\n",
    "        return response\n",
    "    return get_answer_chat\n",
    "\n",
    "index_path = os.path.join(os.getcwd(), \"enriched_index\")\n",
    "graph = build_workflow(index_path)\n",
    "\n",
    "gr.ChatInterface(\n",
    "    get_answer_func(graph),\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    title=\"Agent\",\n",
    "    description=\"Ask me any question\",\n",
    "    theme=\"ocean\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# CHECK ERROR FUNCTION BY FUNCTION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHUNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_enrichment_index(files=DATA_FOLDER, documents=None):\n",
    "    \"\"\"\n",
    "    Added processing logs to check if files are processed functionally\n",
    "    \n",
    "    Args:\n",
    "        files: Path to data folder or list of file paths (default: DATA_FOLDER)\n",
    "        documents: Optional pre-loaded documents (default: None)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (VectorStoreIndex, dict) - Enriched index with metadata and processing logs\n",
    "    \"\"\"\n",
    "    nest_asyncio.apply()\n",
    "    \n",
    "    os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "    os.makedirs(METADATA_ENRICHMENT_INDEX_DIR, exist_ok=True)\n",
    "    \n",
    "    # Initialize logging dictionary\n",
    "    processing_log = {\n",
    "        'processed_files': [],\n",
    "        'total_documents': 0,\n",
    "        'nodes_generated': 0,\n",
    "        'processing_details': []\n",
    "    }\n",
    "    \n",
    "    # Initialize extractors and transformations\n",
    "    extractors = [\n",
    "        TitleExtractor(nodes=5, llm=Settings.llm),\n",
    "        KeywordExtractor(keywords=10, llm=Settings.llm)\n",
    "    ]\n",
    "    transformations = [Settings.node_parser] + extractors\n",
    "    pipeline = IngestionPipeline(transformations=transformations)\n",
    "    docs_nodes = []\n",
    "    \n",
    "    if documents:\n",
    "        # Handle pre-loaded documents\n",
    "        if isinstance(documents, list):\n",
    "            doc_count = len(documents)\n",
    "        else:\n",
    "            doc_count = 1\n",
    "            documents = [documents]\n",
    "            \n",
    "        processing_log['total_documents'] = doc_count\n",
    "        new_nodes = pipeline.run(documents=documents)\n",
    "        docs_nodes.extend(new_nodes)\n",
    "        processing_log['nodes_generated'] += len(new_nodes)\n",
    "        \n",
    "    else:\n",
    "        # Get PDF files from the data folder\n",
    "        if isinstance(files, str):\n",
    "            if os.path.isdir(files):\n",
    "                file_paths = glob(os.path.join(files, \"*.pdf\"))\n",
    "            else:\n",
    "                file_paths = [files]\n",
    "        else:\n",
    "            file_paths = files\n",
    "            \n",
    "        # Log the search path\n",
    "        processing_log['data_folder'] = DATA_FOLDER\n",
    "        processing_log['total_documents'] = len(file_paths)\n",
    "        \n",
    "        print(f\"\\nSearching for PDF files in: {DATA_FOLDER}\")\n",
    "        \n",
    "        if not file_paths:\n",
    "            print(f\"No PDF files found in {DATA_FOLDER}\")\n",
    "            processing_log['processing_details'].append({\n",
    "                'status': 'warning',\n",
    "                'message': f'No PDF files found in directory: {DATA_FOLDER}'\n",
    "            })\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            if not os.path.exists(file_path):\n",
    "                processing_log['processing_details'].append({\n",
    "                    'file_path': file_path,\n",
    "                    'file_name': os.path.basename(file_path),\n",
    "                    'status': 'failed',\n",
    "                    'error': f'File does not exist: {file_path}'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                print(f\"Processing: {os.path.basename(file_path)}\")\n",
    "                reader = SimpleDirectoryReader(input_files=[file_path])\n",
    "                docs = reader.load_data()\n",
    "                \n",
    "                # Log document details\n",
    "                doc_info = {\n",
    "                    'file_path': file_path,\n",
    "                    'file_name': os.path.basename(file_path),\n",
    "                    'file_size': f\"{os.path.getsize(file_path) / 1024:.2f} KB\",\n",
    "                }\n",
    "                \n",
    "                # Process document\n",
    "                new_nodes = pipeline.run(documents=docs)\n",
    "                docs_nodes.extend(new_nodes)\n",
    "                \n",
    "                # Update log with success details\n",
    "                doc_info.update({\n",
    "                    'nodes_generated': len(new_nodes),\n",
    "                    'status': 'success'\n",
    "                })\n",
    "                processing_log['processed_files'].append(doc_info)\n",
    "                processing_log['nodes_generated'] += len(new_nodes)\n",
    "                print(f\"Generated {len(new_nodes)} nodes\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {os.path.basename(file_path)}: {str(e)}\")\n",
    "                processing_log['processing_details'].append({\n",
    "                    'file_path': file_path,\n",
    "                    'file_name': os.path.basename(file_path),\n",
    "                    'status': 'failed',\n",
    "                    'error': str(e)\n",
    "                })\n",
    "    \n",
    "\n",
    "    index = VectorStoreIndex(nodes=docs_nodes,embed_model=Settings.embed_model)\n",
    "    index.storage_context.persist(persist_dir=METADATA_ENRICHMENT_INDEX_DIR)\n",
    "    \n",
    "    # Add final statistics\n",
    "    processing_log['total_nodes'] = len(docs_nodes)\n",
    "    processing_log['index_path'] = METADATA_ENRICHMENT_INDEX_DIR\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nDocument Processing Summary:\")\n",
    "    print(f\"Total documents processed successfully: {len(processing_log['processed_files'])}\")\n",
    "    print(f\"Total nodes generated: {processing_log['nodes_generated']}\")\n",
    "    print(f\"Index saved to: {METADATA_ENRICHMENT_INDEX_DIR}\")\n",
    "    \n",
    "    if processing_log['processed_files']:\n",
    "        print(\"\\nSuccessfully processed files:\")\n",
    "        for file_info in processing_log['processed_files']:\n",
    "            print(f\"- {file_info['file_name']}: {file_info.get('nodes_generated', 'N/A')} nodes\")\n",
    "    \n",
    "    if processing_log['processing_details']:\n",
    "        print(\"\\nIssues encountered:\")\n",
    "        for file_info in processing_log['processing_details']:\n",
    "            if 'message' in file_info:\n",
    "                print(f\"- {file_info['message']}\")\n",
    "            else:\n",
    "                print(f\"- {file_info['file_name']}: {file_info['error']}\")\n",
    "    \n",
    "    return index, processing_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for PDF files in: c:\\Users\\Yueyi\\OneDrive\\桌面\\Cneutral\\codes\\LLM tool\\docs\n",
      "Processing: 797324_e_SOL_Sustainability Report 2023_240422.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.45it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.48it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.15it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.13it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.35it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.61it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.48it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.31it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.65it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.64it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.58it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.68it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.38it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.95it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.20it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.91it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.18it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.14it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.28it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.84it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.37it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.70it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.92it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.01it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.23it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.63it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.68it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.56it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.66it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.27it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.70it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.95it/s]\n",
      "100%|██████████| 5/5 [00:02<00:00,  2.34it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.47it/s]\n",
      "100%|██████████| 5/5 [01:01<00:00, 12.21s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.43it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.02it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.68it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.01it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.65it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.58it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.52it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.56it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.38it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.48it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.54it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.85it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.71it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.64it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.51it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.50it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.66it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.54it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.58it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.91it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.96it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.57it/s]\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.26s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.14it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.85it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.12it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.94it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.72it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.22it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.45it/s]\n",
      "100%|██████████| 1148/1148 [04:19<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1148 nodes\n",
      "Processing: 797418_GCCP-Sustainability_Report_FY2023.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.88it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.19it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.71it/s]\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.53it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.31it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.76it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.09it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.66it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.75it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.58it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.86it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.72it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.14it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "100%|██████████| 262/262 [00:56<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 262 nodes\n",
      "Processing: cvx_portfolio.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.31it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.86it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.43it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.81it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.14it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.04it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.87it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.36it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.72it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.18it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.23it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.47it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.15it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.49it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.10it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.58it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.42it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.82it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.05it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.16it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.97it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.17it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.79it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.27it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.60it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.49it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.83it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.93it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.73it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.43it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.55it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.55it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.85it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.36it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.51it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.24it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.25it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.48it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.43it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.39it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.41it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.22it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.41it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.10it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.54it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.70it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.30it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.62it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.56it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.80it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.54it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.01it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.42it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.08it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.20it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.56it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.41it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.80it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.54it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.66it/s]\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.46it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.75it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.37it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.04it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.73it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.73it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.83it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.64it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.80it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.56it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.09it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.32it/s]\n",
      "100%|██████████| 1809/1809 [06:33<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1809 nodes\n",
      "Processing: MachineLearning-Lecture01.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.79it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.82it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.65it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.20it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.05it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.51it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.55it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.42it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.29it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.91it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.65it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.57it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.77it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.01it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.87it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.84it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.25it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  4.50it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  5.92it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.17it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "100%|██████████| 564/564 [01:53<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 564 nodes\n",
      "\n",
      "Document Processing Summary:\n",
      "Total documents processed successfully: 4\n",
      "Total nodes generated: 3783\n",
      "Index saved to: c:\\Users\\Yueyi\\OneDrive\\桌面\\Cneutral\\codes\\LLM tool\\enriched_index\n",
      "\n",
      "Successfully processed files:\n",
      "- 797324_e_SOL_Sustainability Report 2023_240422.pdf: 1148 nodes\n",
      "- 797418_GCCP-Sustainability_Report_FY2023.pdf: 262 nodes\n",
      "- cvx_portfolio.pdf: 1809 nodes\n",
      "- MachineLearning-Lecture01.pdf: 564 nodes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x26b0248f3d0>,\n",
       " {'processed_files': [{'file_path': 'c:\\\\Users\\\\Yueyi\\\\OneDrive\\\\桌面\\\\Cneutral\\\\codes\\\\LLM tool\\\\docs\\\\797324_e_SOL_Sustainability Report 2023_240422.pdf',\n",
       "    'file_name': '797324_e_SOL_Sustainability Report 2023_240422.pdf',\n",
       "    'file_size': '11688.18 KB',\n",
       "    'nodes_generated': 1148,\n",
       "    'status': 'success'},\n",
       "   {'file_path': 'c:\\\\Users\\\\Yueyi\\\\OneDrive\\\\桌面\\\\Cneutral\\\\codes\\\\LLM tool\\\\docs\\\\797418_GCCP-Sustainability_Report_FY2023.pdf',\n",
       "    'file_name': '797418_GCCP-Sustainability_Report_FY2023.pdf',\n",
       "    'file_size': '326.74 KB',\n",
       "    'nodes_generated': 262,\n",
       "    'status': 'success'},\n",
       "   {'file_path': 'c:\\\\Users\\\\Yueyi\\\\OneDrive\\\\桌面\\\\Cneutral\\\\codes\\\\LLM tool\\\\docs\\\\cvx_portfolio.pdf',\n",
       "    'file_name': 'cvx_portfolio.pdf',\n",
       "    'file_size': '771.07 KB',\n",
       "    'nodes_generated': 1809,\n",
       "    'status': 'success'},\n",
       "   {'file_path': 'c:\\\\Users\\\\Yueyi\\\\OneDrive\\\\桌面\\\\Cneutral\\\\codes\\\\LLM tool\\\\docs\\\\MachineLearning-Lecture01.pdf',\n",
       "    'file_name': 'MachineLearning-Lecture01.pdf',\n",
       "    'file_size': '63.04 KB',\n",
       "    'nodes_generated': 564,\n",
       "    'status': 'success'}],\n",
       "  'total_documents': 4,\n",
       "  'nodes_generated': 3783,\n",
       "  'processing_details': [],\n",
       "  'data_folder': 'c:\\\\Users\\\\Yueyi\\\\OneDrive\\\\桌面\\\\Cneutral\\\\codes\\\\LLM tool\\\\docs',\n",
       "  'total_nodes': 3783,\n",
       "  'index_path': 'c:\\\\Users\\\\Yueyi\\\\OneDrive\\\\桌面\\\\Cneutral\\\\codes\\\\LLM tool\\\\enriched_index'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_enrichment_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded existing index with 3783 documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x26b689064d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def llama_index_chunk_pdf(files=DATA_FOLDER, index_dir=METADATA_ENRICHMENT_INDEX_DIR):\n",
    "    \"\"\"\n",
    "    Load/create new one from PDF files with validation checks.\n",
    "    \n",
    "    Args:\n",
    "        files: Directory containing PDF files\n",
    "        index_dir: Directory for storing the index\n",
    "        \n",
    "    Returns:\n",
    "        Loaded or newly created index\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If index validation fails\n",
    "    \"\"\"\n",
    "    # Load existing index if available\n",
    "    if os.path.exists(index_dir):\n",
    "        try:\n",
    "            index = load_index_from_storage(StorageContext.from_defaults(persist_dir=index_dir))\n",
    "            \n",
    "            # Validate the loaded index\n",
    "            if index is None:\n",
    "                raise ValueError(\"Index loaded as None\")\n",
    "                \n",
    "            # Check if index has documents\n",
    "            doc_count = len(index.docstore.docs)\n",
    "            if doc_count == 0:\n",
    "                raise ValueError(\"Loaded index contains no documents\")\n",
    "                \n",
    "            print(f\"Successfully loaded existing index with {doc_count} documents\")\n",
    "            return index\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading existing index: {str(e)}\")\n",
    "            print(\"Falling back to creating new index...\")\n",
    "    \n",
    "    # Create new index from PDF files\n",
    "    try:\n",
    "        file_paths = [os.path.join(files, f) for f in os.listdir(files) if f.endswith('.pdf')]\n",
    "        \n",
    "        if not file_paths:\n",
    "            raise ValueError(f\"No PDF files found in {files}\")\n",
    "            \n",
    "        print(f\"Found {len(file_paths)} PDF files\")\n",
    "        \n",
    "        documents = SimpleDirectoryReader(input_files=file_paths).load_data()\n",
    "        if not documents:\n",
    "            raise ValueError(\"No documents loaded from PDF files\")\n",
    "            \n",
    "        document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "        \n",
    "        index = metadata_enrichment_index(documents=document)\n",
    "        if index is None:\n",
    "            raise ValueError(\"Failed to create new index\")\n",
    "            \n",
    "        print(f\"Successfully created new index from {len(file_paths)} PDF files\")\n",
    "        return index\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to create new index: {str(e)}\")\n",
    "    \n",
    "llama_index_chunk_pdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 'nodes_generated': 3783 == loaded documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded existing index with 3783 documents\n"
     ]
    }
   ],
   "source": [
    "index_test = llama_index_chunk_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:starting to create sentence engine...\n",
      "INFO:__main__:postprocessor created successfully\n",
      "INFO:__main__:sentence window engine created successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x26bc5e78e90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Optional, Union\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.core.question_gen import LLMQuestionGenerator\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "# add log\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_sentence_window_query_engine(sentence_index, similarity_top_k=6) -> Optional[Union[str, Exception]]:\n",
    "    \"\"\"create sentence query engine, return engine\n",
    "    return with log\"\"\"\n",
    "    try:\n",
    "        logger.info(\"starting to create sentence engine...\")\n",
    "        \n",
    "        if sentence_index is None:\n",
    "            raise ValueError(\"sentence_index cannot be None\")\n",
    "        if similarity_top_k < 1:\n",
    "            raise ValueError(\"similarity_top_k must be greater than 0\")\n",
    "            \n",
    "        postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "        logger.info(\"postprocessor created successfully\")\n",
    "        \n",
    "        sentence_window_engine = sentence_index.as_query_engine(\n",
    "            similarity_top_k=similarity_top_k,\n",
    "            node_postprocessors=[postproc]\n",
    "        )\n",
    "        \n",
    "        if sentence_window_engine is None:\n",
    "            raise ValueError(\"fail to create sentence window engine\")\n",
    "            \n",
    "        logger.info(\"sentence window engine created successfully\")\n",
    "        return sentence_window_engine\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"error in creating postprocess engine: {str(e)}\")\n",
    "        raise\n",
    "get_sentence_window_query_engine(index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_engine(engine, verbose=False):\n",
    "    \"\"\"create final engine based on the sentence engine, with log\"\"\"\n",
    "    try:\n",
    "        logger.info(\"start to create final engine...\")\n",
    "        \n",
    "        if engine is None:\n",
    "            raise ValueError(\"input engine cannot be None\")\n",
    "        \n",
    "        # create generator\n",
    "        question_gen = LLMQuestionGenerator.from_defaults(\n",
    "            llm=Settings.llm,\n",
    "            prompt_template_str=\"\"\"\n",
    "                Instead of giving a question, always prefix the question\n",
    "                with: 'By first identifying and quoting the most relevant sources, '.\n",
    "                \"\"\" + DEFAULT_SUB_QUESTION_PROMPT_TMPL,\n",
    "        )\n",
    "        logger.info(\"question generator created\")\n",
    "        \n",
    "        # create final engine\n",
    "        final_query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "            query_engine_tools=[\n",
    "                QueryEngineTool(\n",
    "                    query_engine=engine,\n",
    "                    metadata=ToolMetadata(\n",
    "                        name=\"docs\",\n",
    "                        description=\"ESG information and portfolio constructions on companies.\",\n",
    "                    ),\n",
    "                )\n",
    "            ],\n",
    "            question_gen=question_gen,\n",
    "            use_async=False,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # validate finel engine\n",
    "        if final_query_engine is None:\n",
    "            raise ValueError(\"failed to create final engine\")\n",
    "            \n",
    "        logger.info(\"final engine created\")\n",
    "        return final_query_engine\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"error in building final engine: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama_index_retriever_tool(index_path: str, index_type='sentence', similarity_top_k=6):\n",
    "    \"\"\"\n",
    "    create retriever tool, returns engine\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"loading index from{index_path}...\")\n",
    "        \n",
    "        # validate input\n",
    "        if not isinstance(index_path, str) or not index_path:\n",
    "            raise ValueError(\"invalid index path\")\n",
    "        if similarity_top_k < 1:\n",
    "            raise ValueError(\"similarity_top_k must be greater than 0\")\n",
    "        \n",
    "        # load index\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "        index = load_index_from_storage(storage_context)\n",
    "        \n",
    "        # validate index\n",
    "        if index is None:\n",
    "            raise ValueError(\"failed to load index\")\n",
    "        \n",
    "        logger.info(\"index loaded successfully\")\n",
    "        \n",
    "        # create the engine\n",
    "        query_engine = get_sentence_window_query_engine(index, similarity_top_k) if 'sentence' in index_type else index.as_query_engine(similarity_top_k=similarity_top_k)\n",
    "        query_engine = final_engine(query_engine, verbose=True)\n",
    "        \n",
    "        logger.info(\"query engine created successfully\")\n",
    "\n",
    "        @tool\n",
    "        def engine(query=''):\n",
    "            \"\"\"RAG query tool\"\"\"\n",
    "            try:\n",
    "                if not query:\n",
    "                    logger.warning(\"recieved empty queries\")\n",
    "                    return \"queries cannot be empty\"\n",
    "                \n",
    "                logger.info(f\"processing: {query}\")\n",
    "                response = query_engine.query(query)\n",
    "                \n",
    "                # test response\n",
    "                if response is None:\n",
    "                    raise ValueError(\"returned empty response\")\n",
    "                \n",
    "                logger.info(\"response finished\")\n",
    "                print(f'---RAG---:\\n {response}')\n",
    "                return response\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"error in responsing: {str(e)}\")\n",
    "                raise\n",
    "        \n",
    "        return engine\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"error in creating retriever: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loading index fromc:\\Users\\Yueyi\\OneDrive\\桌面\\Cneutral\\codes\\LLM tool\\enriched_index...\n",
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "INFO:__main__:index loaded successfully\n",
      "INFO:__main__:starting to create sentence engine...\n",
      "INFO:__main__:postprocessor created successfully\n",
      "INFO:__main__:sentence window engine created successfully\n",
      "INFO:__main__:start to create final engine...\n",
      "INFO:__main__:question generator created\n",
      "INFO:__main__:final engine created\n",
      "INFO:__main__:query engine created successfully\n",
      "INFO:__main__:start to create final engine...\n",
      "INFO:__main__:question generator created\n",
      "INFO:__main__:final engine created\n"
     ]
    }
   ],
   "source": [
    "engine_test = llama_index_retriever_tool(METADATA_ENRICHMENT_INDEX_DIR)\n",
    "engine_test_test = final_engine(engine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_query_engine_response(response: Any) -> bool:\n",
    "    \"\"\"\n",
    "    Validate response from query engine\n",
    "    \n",
    "    Args:\n",
    "        response: Response from query engine\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if response is valid\n",
    "    \"\"\"\n",
    "    if response is None:\n",
    "        logging.error(\"Query engine response cannot be None\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def grade_documents(state) -> Literal[\"generate\", \"rewrite\", \"generate_no_ans\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state including index_path and messages\n",
    "\n",
    "    Returns:\n",
    "        str: Decision on next action - \"generate\", \"rewrite\", or \"generate_no_ans\"\n",
    "    \"\"\"\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "    \n",
    "    try:\n",
    "        # Validate input state format\n",
    "        if not validate_state(state):\n",
    "            raise ValueError(\"Invalid state format\")\n",
    "        \n",
    "        messages = state[\"messages\"]\n",
    "        question = messages[0].content\n",
    "        print('Question:', question)\n",
    "        \n",
    "        # Use llama-index for retrieval if index_path is provided\n",
    "        if \"index_path\" in state:\n",
    "            # Create retriever with increased similarity_top_k for better coverage\n",
    "            retriever = llama_index_retriever_tool(\n",
    "                index_path=state[\"index_path\"],\n",
    "                index_type='sentence',\n",
    "                similarity_top_k=10  # Increased from 6 to 10\n",
    "            )\n",
    "            \n",
    "            # Get retrieval results and validate\n",
    "            retrieval_response = retriever(question)\n",
    "            if not validate_query_engine_response(retrieval_response):\n",
    "                raise ValueError(\"Invalid retrieval response\")\n",
    "                \n",
    "            docs = str(retrieval_response)\n",
    "            \n",
    "            # Normalize question and response for better matching\n",
    "            question_lower = question.lower()\n",
    "            docs_lower = docs.lower()\n",
    "            \n",
    "            # Extract year from question for temporal relevance\n",
    "            import re\n",
    "            year_match = re.search(r'20\\d{2}', question)\n",
    "            if year_match:\n",
    "                year = year_match.group()\n",
    "                \n",
    "                # Check if the document contains both the year and some numeric value\n",
    "                has_year = year in docs_lower\n",
    "                has_numbers = bool(re.search(r'(?:rm|myr|rp)?\\s*\\d+(?:\\.\\d+)?(?:\\s*(?:million|m|billion|b))?', docs_lower))\n",
    "                \n",
    "                if has_year and has_numbers:\n",
    "                    print(\"---DECISION: DOCS RELEVANT (Contains Year and Numbers)---\")\n",
    "                    print(\"docs:\")\n",
    "                    print(docs)\n",
    "                    return \"generate\"\n",
    "            \n",
    "            # Check for \"no information\" type responses\n",
    "            no_info_phrases = [\n",
    "                \"do not contain\",\n",
    "                \"does not specify\",\n",
    "                \"cannot provide\",\n",
    "                \"no information\",\n",
    "                \"not available\",\n",
    "                \"could not find\",\n",
    "                \"not found\",\n",
    "                \"therefore, i cannot\"\n",
    "            ]\n",
    "            \n",
    "            if any(phrase in docs_lower for phrase in no_info_phrases):\n",
    "                print(\"---DECISION: DOCS NOT RELEVANT (No Information Found)---\")\n",
    "                print(\"docs:\")\n",
    "                print(docs)\n",
    "                if state[\"attempt_num\"] < MAX_ATTEMPT:\n",
    "                    return \"rewrite\"\n",
    "                else:\n",
    "                    return \"generate_no_ans\"\n",
    "                \n",
    "        else:\n",
    "            docs = messages[-1].content\n",
    "            \n",
    "        print(\"Retrieved docs:\", docs)\n",
    "        \n",
    "        # Set up relevance scoring with improved prompt\n",
    "        class grade(BaseModel):\n",
    "            binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
    "        \n",
    "        model = ChatOpenAI(temperature=0.1, model=MODEL_NAME, streaming=True)\n",
    "        llm_with_tool = model.with_structured_output(grade)\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question about financial data. \\n \n",
    "            Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "            Here is the user question: {question} \\n\n",
    "            \n",
    "            For financial or ESG related questions, grade the document as relevant if it contains:\n",
    "            1. Specific numeric values (like revenue, profit, etc.) for the requested time period\n",
    "            2. Financial figures with currency indicators (USD, MYR, RM, etc.)\n",
    "            3. Year-specific financial information that matches the question\n",
    "            4. Comparative financial data between years\n",
    "            \n",
    "            The document should be considered relevant even if it needs some interpretation \n",
    "            (e.g., if asking about 2023 and document mentions 'FY2023' or 'current year'; ).\n",
    "            \n",
    "            If the document only states that information is not found or not available, grade it as not relevant.\n",
    "            Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question.\"\"\",\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "        )\n",
    "        chain = prompt | llm_with_tool\n",
    "\n",
    "        scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "        if not hasattr(scored_result, 'binary_score'):\n",
    "            raise ValueError(\"Invalid scoring result\")\n",
    "            \n",
    "        score = scored_result.binary_score\n",
    "\n",
    "        if score == \"yes\":\n",
    "            print(\"---DECISION: DOCS RELEVANT---\")\n",
    "            print(\"docs:\")\n",
    "            print(docs)\n",
    "            return \"generate\"\n",
    "        elif state[\"attempt_num\"] < MAX_ATTEMPT:\n",
    "            print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
    "            print(score)\n",
    "            print(\"docs:\")\n",
    "            print(docs)\n",
    "            return \"rewrite\"\n",
    "        else:\n",
    "            print(\"---DECISION: DOCS NOT RELEVANT, MAX_ATTEMPT achieved---\")\n",
    "            print(score)\n",
    "            print(\"docs:\")\n",
    "            print(docs)\n",
    "            return \"generate_no_ans\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in grade_documents: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loading index fromc:\\Users\\Yueyi\\OneDrive\\桌面\\Cneutral\\codes\\LLM tool\\enriched_index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK RELEVANCE---\n",
      "Question: What's Public Shareholders' share for SOL?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "INFO:__main__:index loaded successfully\n",
      "INFO:__main__:starting to create sentence engine...\n",
      "INFO:__main__:postprocessor created successfully\n",
      "INFO:__main__:sentence window engine created successfully\n",
      "INFO:__main__:start to create final engine...\n",
      "INFO:__main__:question generator created\n",
      "INFO:__main__:final engine created\n",
      "INFO:__main__:query engine created successfully\n",
      "INFO:__main__:processing: What's Public Shareholders' share for SOL?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[docs] Q: By first identifying and quoting the most relevant sources, what is the percentage of public shareholders' ownership in SOL?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;237;90;200m[docs] A: The percentage of public shareholders' ownership in Shui On Land (SOL) is 43.77%. This information is found in the excerpt stating, \"Shui On Land is jointly owned by the Shui On Group and public shareholders, with a 100% ownership stake shared between them. Shui On Group 56.23% Public Shareholders 43.77%.\"\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[docs] Q: By first identifying and quoting the most relevant sources, what is the total number of shares outstanding for SOL?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;90;149;237m[docs] A: The provided excerpts do not contain specific information regarding the total number of shares outstanding for Shui On Land Limited (SOL). Therefore, I cannot provide that information based on the available context.\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[docs] Q: By first identifying and quoting the most relevant sources, what are the recent changes in SOL's shareholder structure?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;11;159;203m[docs] A: The recent changes in Shui On Land's (SOL) shareholder structure indicate that the company is jointly owned by the Shui On Group and public shareholders, with a 100% ownership stake shared between them. Specifically, the Shui On Group holds a 56.23% stake, while public shareholders account for 43.77%. This structure reflects a significant commitment to maintaining a balance between private and public ownership.\n",
      "\n",
      "Additionally, there has been a focus on enhancing corporate governance and stakeholder engagement, which may influence shareholder dynamics. The report emphasizes the importance of strong sustainability performance to attract shareholders who are focused on creating long-term value. \n",
      "\n",
      "These insights highlight the current ownership distribution and the strategic emphasis on sustainability as a means to engage and retain shareholders.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:response finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RAG---:\n",
      " Public shareholders' share for Shui On Land (SOL) is 43.77%.\n",
      "Retrieved docs: Public shareholders' share for Shui On Land (SOL) is 43.77%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---DECISION: DOCS RELEVANT---\n",
      "docs:\n",
      "Public shareholders' share for Shui On Land (SOL) is 43.77%.\n",
      "Grade result: generate\n"
     ]
    }
   ],
   "source": [
    "test_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"What's Public Shareholders' share for SOL?\"),\n",
    "    ],\n",
    "    \"attempt_num\": 0,\n",
    "    \"index_path\": METADATA_ENRICHMENT_INDEX_DIR   \n",
    "}\n",
    "\n",
    "# test\n",
    "try:\n",
    "    result = grade_documents(test_state)\n",
    "    print(f\"Grade result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Test failed: {str(e)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
